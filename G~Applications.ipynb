{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<p style=\"color:#FFF; background:#06D; padding:12px; font-size:20px; font-style:italic; text-align:center\">\n",
"<span style=\"width:49%; display:inline-block; text-align:left\">Version 2025-06</span>\n",
"<span style=\"width:49%; display:inline-block; text-align:right\">Licence CC–BY–NC–ND</span>\n",
"<span style=\"font-size:40px; font-style:normal\"><b>EXERCICES : APPLICATIONS</b></span><br>\n",
"<span style=\"width:49%; display:inline-block; text-align:left\">Christophe Schlick</span>\n",
"<span style=\"width:49%; display:inline-block; text-align:right\">schlick ಄ u<b>-</b>bordeaux • fr</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "> ***ATTENTION : Les exercices de ce notebook ne seront pas traité en TD, mais pourront être fait en travail personnel et mis sur votre espace www au CREMI, selon les modalités définies sur le site web du cours***\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'objectif de cette feuille d'exercices est de combiner les différentes notions abordées dans les chapitres précédents, pour tenter de résoudre des problèmes plus ambitieux de traitements de données, définis sous la forme d'études de cas dans des domaines très variés. A la différence des feuilles d'exercices précédentes, aucune indication ne sera donnée sur la marche à suivre pour écrire le code Python permettant de résoudre chaque exercice. Il faudra effectuer une ***véritable démarche d'ingénieur en sciences des données***, en appliquant les cinq étapes classiques :\n",
    "\n",
    "- **Fetch** : récupérer les données, éventuellement provenant de sources différentes\n",
    "- **Clean** : nettoyer les données, supprimer les données aberrantes et les données inutiles\n",
    "- **Structure** : structurer les données de manière optimale en fonction des questions posées\n",
    "- **Model** : définir un modèle formel permettant de répondre aux questions posées\n",
    "- **Analyze** : appliquer le modèle sur les données et commenter le résultat obtenu\n",
    "\n",
    "> **Note :** *Comme cette UE s'intéresse principalement aux trois premiers maillons de cette chaîne de traitement, le travail à réaliser sur les parties modélisation et analyse restera très simple. Vous aurez l'occasion, dans vos autres UE, d'apprendre et de mettre en oeuvre des outils plus complexes et plus puissants sur ces deux maillons finaux*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as mp; mp.style.use('default')\n",
    "import seaborn as sb; sb.set_style('ticks')\n",
    "import plotly.express as px\n",
    "import warnings; warnings.filterwarnings('ignore') # suppression des 'warning' de l'interpréteur"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"padding:16px; color:#FFF; background:#06D\">Exercice G1 - Nomenclature des pays et territoires</h2>\n",
    "\n",
    "Sur le site [**data.gouv.fr**](https://www.data.gouv.fr) regroupant les données en accès libre mises à disposition par l'administration française, se trouve une base de données, appelée [**Code Officiel Géographique**](https://www.data.gouv.fr/fr/datasets/code-officiel-geographique-cog), qui recense les **dénominations administratives officielles des entités géographiques**, allant des communes jusqu'aux pays et territoires étrangers. Parmi les nombreux fichiers fournis par la base de données, on va s'intéresser uniquement aux deux fichiers CSV suivants : [**Pays et territoires étrangers**](https://www.data.gouv.fr/fr/datasets/r/e31e4f85-635e-4ec9-8d88-c4d6c0c586bb) et [**Pays et territoires étrangers depuis 1943**](https://www.data.gouv.fr/fr/datasets/r/150889d3-ffda-4ea5-8709-6ee67415294f) qui se focalisent sur les noms des pays du monde. Le premier fichier contient les noms et les [**codes ISO-3166**](https://fr.wikipedia.org/wiki/ISO_3166) des 228 territoires internationaux reconnus par la France en 2024 ([**cliquer ici**](https://www.insee.fr/fr/information/7766585#titre-bloc-25) pour avoir les explications concernant les différentes colonnes de cette table). Le second fichier contient les dénominations successives de ces pays et territoires qui ont été utilisées depuis 1943, notamment lors des cissions ou regroupements de pays, ou lors des changements de régimes politiques ([**cliquer ici**](https://www.insee.fr/fr/information/7766585#titre-bloc-30) pour les détails des différentes colonnes).\n",
    "\n",
    "Ecrire le code Python permettant de récupérer les données sur ces sites, et d'effectuer les traitements nécessaires pour répondre aux questions suivantes :\n",
    "\n",
    "- Séparer la table fournie par le premier fichier en deux fichiers CSV : le premier **`pays.csv`** regroupe les lignes correspondant aux ***Etats autonomes*** (France, Allemagne, etc) et le second **`territoires.csv`** regroupe les lignes correspondant aux ***territoires auxiliaires rattachés à un Etat autonome*** (par exemple, l'île de Jersey est rattachée au Royaume-Uni, les îles Féroé au Danemark, etc). Chacun des deux fichiers sera trié dans l'ordre alphabétique des codes ISO-3166 à 3 lettres (vous pourrez enlever les colonnes de la table initiale qui vous semblent inutiles)\n",
    "- En se limitant aux Etats autonomes, calculer et afficher l'histogramme du nombre de dénominations officielles qu'a connu chaque pays depuis 1943 et identifier les pays ayant changé le plus souvent de nom\n",
    "- Pour chaque année depuis 1943, créer deux séries chronologiques recensant respectivement le nombre total de pays autonomes et le nombre de territoires rattachés, et les afficher sur une même figure **matplotlib** ou **seaborn**, en choisissant le type le visualisation le mieux adapté\n",
    "- Récupérer sur internet (à vous de trouver un site adéquat) une table présentant le nom du continent auquel appartient chacun des pays et territoires de la liste, et utiliser ces informations pour rajouter une colonne **`CONTINENT`** dans les fichiers **`pays.csv`** et **`territoires.csv`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h2 style=\"padding:16px; color:#FFF; background:#06D\">Exercice G2 - Répartition des médailles pour Paris 2024</h2>\n",
    "\n",
    "Le site web [**Olympics**](https://olympics.com) récapitule l'ensemble des médailles obtenues aux [**Jeux Olympiques**](https://olympics.com/fr/paris-2024/medailles) et [**Jeux Paralympiques**](https://olympics.com/fr/paris-2024/jeux-paralympiques/medailles) de Paris 2024, en fournissant un classement par pays, par sport ou par athlète. Le site Wikipedia fournit des données similaires avec un classement des médailles ***par pays***, soit en [**olympique**](https://fr.wikipedia.org/wiki/Tableau_des_m%C3%A9dailles_des_Jeux_olympiques_d%27%C3%A9t%C3%A9_de_2024)\n",
    "soit en [**paralympique**](https://fr.wikipedia.org/wiki/Tableau_des_m%C3%A9dailles_des_Jeux_paralympiques_d%27%C3%A9t%C3%A9_de_2024), et un autre ***par sport et par athlète***, soit en [**olympique**](https://fr.wikipedia.org/wiki/Liste_des_m%C3%A9daill%C3%A9s_aux_Jeux_olympiques_d%27%C3%A9t%C3%A9_de_2024) soit en [**paralympique**](https://fr.wikipedia.org/wiki/Liste_des_m%C3%A9daill%C3%A9s_aux_Jeux_paralympiques_d%27%C3%A9t%C3%A9_de_2024)\n",
    "\n",
    "Ecrire le code Python permettant de récupérer les données sur ces sites, et d'effectuer les traitements nécessaires pour répondre aux questions suivantes :\n",
    "\n",
    "- Donner la liste des sports pour lesquels il existe au moins un ou une athlète ayant obtenu deux médailles ou plus (classer cette liste de manière décroissante, en fonction du nombre d'athlètes multi-médaillés pour chaque sport)\n",
    "- Récupérer dans une table **pandas**, la liste de l'ensemble des disciplines sportives des Jeux de Paris 2024, et rajouter deux colonnes de booléens permettant de spécifier pour chaque discipline, d'une part, s'il s'agit d'un **sport individuel ou collectif**, et d'autre part, s'il s'agit d'un **sport de concours** (où le classement général se fait en fonction du temps, de la distance ou du nombre de points obtenus par chaque athlète ou chaque équipe) ou d'un **sport de tournoi** (où le classement final se fait par une série de duels ou de matches entre concurrents). Dans les sports pour lesquels il existe aussi bien des épreuves en individuel et en équipe, il faudra créer deux lignes dans la table, avec une valeur booléenne différente pour la colonne associée.\n",
    "- Utiliser la table précédente pour obtenir un classement du nombre de médailles par pays, en distinguant chacune des quatre catégories : ***individuel par concours, individuel par tournoi, collectif par concours, collectif par tournoi***\n",
    "- Récupérer sur internet (à vous de trouver un site adéquat) une table présentant la population de chaque pays, puis générer un classement décroissant des pays en fonction du ***nombre de médailles d'or, d'argent et de bronze, par million d'habitants*** (valeurs arrondies à deux décimales)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<h2 style=\"padding:16px; color:#FFF; background:#06D\">Exercice G3 - Valorisation des joueurs et des clubs de football</h2>\n",
    "\n",
    "Le site [**TransferMarkt**](https://www.transfermarkt.fr) est une base de données, actualisée une fois par semaine, qui regroupe les valorisations des joueurs et des clubs de football pour l'ensemble des pays adhérant à la [**FIFA**](https://www.fifa.com). Chaque joueur et chaque club est identifié par une clé unique qui permet d'accéder à une page web regroupant toutes les informations les concernant. Par exemple, ***Kylian Mbappé*** est identifié par la clé **342229** et le ***Real Madrid*** est identifié par la clé **418**, ce qui permet de construire les URL suivantes pour accéder à leurs pages respectives sur le site :\n",
    "<center><a href=\"https://www.transfermarkt.fr/kylian-mbappe/profil/spieler/342229\">\n",
    "<b>https://www.transfermarkt.fr/kylian-mbappe/profil/spieler/342229</b></a><br>\n",
    "<a href=\"https://www.transfermarkt.fr/real-madrid/startseite/verein/418\">\n",
    "<b>https://www.transfermarkt.fr/real-madrid/startseite/verein/418</b></a></center><br>\n",
    "\n",
    "Les pages des joueurs et des clubs sont toutes construites sur le même principe. Autrement dit, si on souhaite faire du web scraping et récupérer automatiquement les informations concernant chaque joueur et/ou chaque club, il faut commencer par mettre en place un mécanisme permettant de récupérer les couples ***(nom, clé)*** pour tous les éléments recherchés.\n",
    "\n",
    "Pour y arriver, on va passer par deux pages spécifiques du site qui contiennent respectivement le\n",
    "[**classement des 500 joueurs les plus valorisés**](https://www.transfermarkt.fr/spieler-statistik/wertvollstespieler/marktwertetop) et le [**classement des 100 équipes les plus valorisées**](https://www.transfermarkt.fr/vereins-statistik/wertvollstemannschaften/marktwertetop). Ces pages sont structurées par des tables HTML, ce qui devrait permettre à la fonction **`read_html(url)`** de **pandas** de pouvoir récupérer les tables affichées, sauf que le site incorpore un filtre anti-scraping, et interdit d'utiliser directement la fonction sur les pages concernées :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "url = 'https://www.transfermarkt.fr/vereins-statistik/wertvollstemannschaften/marktwertetop'\n",
    "#data = pd.read_html(url) # la fonction renvoie 'HTTP Error 403: Forbidden' alors que la page existe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Comme on l'a vu au chapitre 10, la solution consiste à changer la valeur de la propriété **User-Agent** fournie par la connexion, pour faire croire au site que la page est demandée par un navigateur web classique et pas par un logiciel de scrapping. La fonction **`fetch(url)`** du module **`tools`** permet de faire cela de manière automatique :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from SRC.tools import fetch\n",
    "data = pd.read_html(fetch(url)) # cette fois-ci, il n'y a plus de message d'erreur\n",
    "data[1].head(8) # on affiche le début de la seconde table de la page qui est celle qui nous intéresse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Le classement des équipes est réparti sur plusieurs pages (4 pages de 25 lignes pour celui des équipes, 20 pages de 25 lignes pour celui des joueurs). Pour récupérer les données des autres pages, il faut modifier l'URL en rajoutant le suffixe **`?page=N`** où **N** représente le numéro de la page :\n",
    "\n",
    "<center><a href=\"https://www.transfermarkt.fr/vereins-statistik/wertvollstemannschaften/marktwertetop?page=2\"><b>https://www.transfermarkt.fr/vereins-statistik/wertvollstemannschaften/marktwertetop?page=2</b></a></center><br>\n",
    "\n",
    "De même, le classement par défaut regroupe toutes les équipes du monde, mais on peut visualiser le classement, pays par pays en rajoutant le numéro du pays dans l'URL avec le suffixe **`?land_id=P`** où **P** représente le numéro du pays :\n",
    "\n",
    "<center><a href=\"https://www.transfermarkt.fr/vereins-statistik/wertvollstemannschaften/marktwertetop?page=1&land_id=50\"><b>https://www.transfermarkt.fr/vereins-statistik/wertvollstemannschaften/marktwertetop?page=1&land_id=50</b></a></center><br>\n",
    "\n",
    "Les numéros des pays utilisent un système propre au site, il faut donc faire quelques expérimentations pour trouver les différents codes, en utilisant les widgets pour modifier le pays et analyser la modification de l'URL que cela engendre.\n",
    "\n",
    "En suivant toutes ces explications, écrire le code Python permettant de récupérer les données sur ces sites, et d'effectuer les traitements nécessaires pour répondre aux questions suivantes :\n",
    "\n",
    "- Calculer la somme des valorisations des équipes participant aux 5 principaux championnats des pays européens (Royaume-Uni, Espagne, Allemagne, Italie, France) et trier ces 5 championnats par valorisation décroissante\n",
    "- Extraire l'âge et la valorisation des 500 joueurs du classement principal et vérifier si on peut établir une corrélation linéaire ou quadratique entre ces deux paramètres\n",
    "- Faire le même traitement mais en séparant les joueurs selon leur nationalité, puis en séparant les joueurs selon le pays du championnat auquel ils participent\n",
    "- Répartir la valorisation des joueurs en fonction de leur poste (gardien de but, milieu offensif, milieu défensif, etc) et afficher les paramètres de statistiques descriptives sur ces différentes catégories\n",
    "- Etablir la liste des joueurs qui ont été sélectionnés plus de 50 fois dans leur équipe nationale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "<h2 style=\"padding:16px; color:#FFF; background:#06D\">Exercice G4 - Pandémie du Covid-19 en Europe</h2>\n",
    "\n",
    "Le [**Coronavirus Resource Center**](https://coronavirus.jhu.edu) de l'Université Johns Hopkins a compilé la plus grande base de données concernant la [**pandémie du Covid-19**](https://fr.wikipedia.org/wiki/Pand%C3%A9mie_de_Covid-19) dont l'intégralité des données ont été mises en ligne sur [**GitHub**](https://github.com/CSSEGISandData/COVID-19). Dans cet exercice, on s'intéresse plus spécifiquement à trois fichiers contenant des séries temporelles, classées par pays (ou par région pour certains pays), et mises à jour quotidiennement entre le 22 janvier 2020 et le 9 mars 2023 :\n",
    "\n",
    "- [**time_series_covid19_confirmed_global.csv**](https://github.com/CSSEGISandData/COVID-19/blob/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_confirmed_global.csv) regroupe le nombre de cas de Covid-19 déclarés\n",
    "- [**time_series_covid19_deaths_global.csv**](https://github.com/CSSEGISandData/COVID-19/blob/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_deaths_global.csv) regroupe le nombre de décès\n",
    "- [**time_series_covid19_recovered_global.csv**](https://github.com/CSSEGISandData/COVID-19/blob/master/csse_covid_19_data/csse_covid_19_time_series/time_series_covid19_recovered_global.csv) regroupe le nombre de guérisons\n",
    "\n",
    "Ecrire le code Python permettant de récupérer ces données sur le site, et d'effectuer les traitements nécessaires pour répondre aux questions suivantes :\n",
    "\n",
    "- Elaguer les 3 fichiers pour ne conserver que les données relatives aux pays européens (au choix, les 27 pays de l'UE ou les 50 pays de l'Europe géographique)\n",
    "- Avec la table des populations des pays utilisée dans l'exercice G2, normaliser les 3 séries temporelles pour obtenir des valeurs par milliers d'habitants plutôt que des valeurs brutes\n",
    "- En utilisant le package **ipywidgets** (cf. chapitre 4), créer des interacteurs permettant de visualiser les valeurs des 3 séries temporelles pour un pays donnée à une date donnée (on pourra utiliser une liste déroulante pour le choix du pays, et un curseur graphique pour le choix de la date)\n",
    "- En utilisant le package **plotly** (cf. chapitre 10), créer une carte interactive permettant de visualiser l'évolution du nombre de cas par milliers d'habitants, par un échelle de couleurs appliquée à chaque pays (pour le choix de la date on rajoutera le même curseur graphique que celui utilisé dans la question précédente)\n",
    "- En utilisant le package **statmodels** (cf. chapitre 9), appliquer un modèle [**ARIMA**](https://machinelearningmastery.com/arima-for-time-series-forecasting-with-python) (Autoregressive integrated moving average) pour analyser et prédire le nombre quotidien nouveaux cas de Covid-19 pour un pays au choix. Appliquer le modèle sur une série partielle et quantifier son efficacité en comparant les valeurs obtenues par prédiction avec les valeurs effectives\n",
    "- En utilisant le package **scipy.optimize** (cf. chapitre 9), appliquer une régression logistique pour prédire la croissance (puis la décroissance) du nombre de cas de Covid-19 pour un pays au choix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "<h2 style=\"padding:16px; color:#FFF; background:#06D\">Exercice G5 - Emission des gaz à effets de serre en Europe</h2>\n",
    "\n",
    "Le [**site de l'EEA**](https://www.eea.europa.eu/fr) *(Agence Européenne de l'Environnement)* contient de nombreux documents compilant différents types de données environnementales de l'Union Européenne. On y trouve notamment une base de données récapitulant l'évolution des [**émissions de gaz à effet de serre**](https://www.eea.europa.eu/data-and-maps/data/data-viewers/greenhouse-gases-viewer) (GES) au sein de l'UE, classées par pays, par secteurs d'activités et par type de GES.\n",
    "\n",
    "L'objectif de l'exercice est d'effectuer une analyse des tendances par pays et par secteurs d'activités, afin de **pouvoir estimer l'évolution de l'émission des GES pour les années à venir**. Vous êtes totalement libres sur les regroupements de données et les modèles de régression à appliquer, la seule contrainte étant de normaliser les émissions par millions d'habitants, pour éviter le biais lié à la taille de chaque pays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO : ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"padding:8px; margin:0px -20px; color:#FFF; background:#06D; text-align:right\">● ● ● </div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
